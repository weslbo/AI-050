{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Azure OpenAI APIs in your applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run library.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In Azure OpenAI, the terms \"Completion,\" \"Embeddings,\" and \"ChatCompletion\" refer to different functionalities provided by the models, and each serves a specific purpose:\n",
       "\n",
       "### Completion\n",
       "- **Purpose:** The \"Completion\" API is designed to generate text based on a given prompt. This can range from generating simple text completions to more complex tasks like writing essays, articles, code, or even summarizing text.\n",
       "- **Usage:** You provide a prompt (a piece of text) to the model, and it predicts and generates the subsequent text.\n",
       "- **Example:** If you provide the prompt \"Once upon a time,\" the model might continue with \"there was a little girl who lived in a village near the forest.\"\n",
       "\n",
       "### Embeddings\n",
       "- **Purpose:** Embeddings are numerical representations of text that capture the meaning and context of words, phrases, or entire documents in a multi-dimensional space. These are useful for various natural language processing tasks such as semantic search, clustering, and classification.\n",
       "- **Usage:** You input text, and the model converts this text into a high-dimensional vector. These vectors can then be used for similarity comparisons, clustering, or feeding into other machine learning models.\n",
       "- **Example:** If you have two sentences like \"I love machine learning\" and \"I enjoy studying AI,\" the embeddings for these sentences would be close to each other in the vector space, indicating similar contextual meaning.\n",
       "\n",
       "### ChatCompletion\n",
       "- **Purpose:** The \"ChatCompletion\" API is tailored for conversational agents and chatbots. It is designed to take a series of messages (a dialogue) as input and generate a response that continues the conversation.\n",
       "- **Usage:** You provide a sequence of message exchanges between a user and the AI, and the model generates an appropriate response to the latest message.\n",
       "- **Example:** In a customer service scenario, if the customer says, \"I can't log into my account,\" the model might respond with \"I'm sorry to hear that. Can you provide me with your username so I can assist you further?\"\n",
       "\n",
       "### Summary\n",
       "- **Completion:** Generates text based on a prompt; used for general text generation tasks.\n",
       "- **Embeddings:** Converts text into numerical vector representations; used for semantic understanding and similarity tasks.\n",
       "- **ChatCompletion:** Generates conversational responses; used for building chatbots and conversational agents.\n",
       "\n",
       "Each of these functionalities leverages the capabilities of the underlying AI models but is optimized for different types of tasks within natural language processing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "In Azure OpenAI, what is the difference between: \n",
    "\n",
    "- Completion\n",
    "- Embeddings\n",
    "- ChatCompletion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To use the Azure OpenAI completions REST endpoint with a prompt, you need to send a POST request to the endpoint with the necessary headers and payload. Below is an example using `curl`.\n",
       "\n",
       "### Prerequisites\n",
       "1. You should have an Azure subscription and an instance of Azure OpenAI service created.\n",
       "2. You should have your endpoint URL and API key ready.\n",
       "\n",
       "### Example `curl` Command\n",
       "\n",
       "Hereâ€™s an example `curl` command that sends a request to the Azure OpenAI completions REST endpoint:\n",
       "\n",
       "```sh\n",
       "curl -X POST https://<your-endpoint>.openai.azure.com/openai/deployments/<your-deployment-id>/completions?api-version=2022-12-01 \\\n",
       "-H \"Content-Type: application/json\" \\\n",
       "-H \"api-key: <your-api-key>\" \\\n",
       "-d '{\n",
       "    \"prompt\": \"Your favorite Shakespeare play is...\",\n",
       "    \"max_tokens\": 50,\n",
       "    \"temperature\": 0.7\n",
       "}'\n",
       "```\n",
       "\n",
       "Replace `<your-endpoint>`, `<your-deployment-id>`, and `<your-api-key>` with your specific values.\n",
       "\n",
       "### Breakdown of the Command\n",
       "- `-X POST`: Specifies that this is a POST request.\n",
       "- `https://<your-endpoint>.openai.azure.com/openai/deployments/<your-deployment-id>/completions?api-version=2022-12-01`: The URL for the Azure OpenAI completions endpoint.\n",
       "  - Replace `<your-endpoint>` with the actual endpoint for your Azure OpenAI service.\n",
       "  - Replace `<your-deployment-id>` with your specific deployment ID.\n",
       "  - The API version (e.g., `2022-12-01`) should match the one you're using.\n",
       "- `-H \"Content-Type: application/json\"`: Sets the content type to JSON.\n",
       "- `-H \"api-key: <your-api-key>\"`: Adds your Azure OpenAI API key to the headers for authentication.\n",
       "- `-d '{...}'`: The JSON payload containing the request parameters.\n",
       "  - `prompt`: The text prompt you provide.\n",
       "  - `max_tokens`: Maximum number of tokens to generate in the response.\n",
       "  - `temperature`: Sampling temperature to use. Higher values means the model will take more risks.\n",
       "\n",
       "### Example Output JSON\n",
       "\n",
       "Below is an example of what the output JSON might look like:\n",
       "\n",
       "```json\n",
       "{\n",
       "    \"id\": \"cmpl-5wW1bFooBarBazQux\",\n",
       "    \"object\": \"text_completion\",\n",
       "    \"created\": 1675862813,\n",
       "    \"model\": \"text-davinci-003\",\n",
       "    \"choices\": [\n",
       "        {\n",
       "            \"text\": \" \\\"Hamlet.\\\" It's a timeless tragedy that deals with complex themes such as betrayal, revenge, and moral corruption. The character of Hamlet himself is a fascinating study of human psychology, making it one of Shakespeare's most enduring and thought-provoking works.\",\n",
       "            \"index\": 0,\n",
       "            \"logprobs\": null,\n",
       "            \"finish_reason\": \"length\"\n",
       "        }\n",
       "    ],\n",
       "    \"usage\": {\n",
       "        \"prompt_tokens\": 5,\n",
       "        \"completion_tokens\": 50,\n",
       "        \"total_tokens\": 55\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "### Notes\n",
       "- The actual JSON response may differ based on the model and the settings you use.\n",
       "- `max_tokens` specifies the maximum length of the completion.\n",
       "- `temperature` controls the creativity of the response.\n",
       "\n",
       "This example should help you get started with using the Azure OpenAI completions REST endpoint using `curl`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Show me an example in curl of using the Azure OpenAI completions REST endpoint. \n",
    "The prompt should be: \"Your favorite Shakespeare play is...\" \n",
    "Include an example output JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! To use the Azure OpenAI embeddings REST endpoint with curl, you'll need to have your Azure OpenAI service key and endpoint. Below is an example of how to make a request to the embeddings endpoint with the prompt \"The food was delicious and the waiter was very friendly...\" using curl.\n",
       "\n",
       "First, replace `{your-endpoint-url}` with your actual Azure OpenAI endpoint URL and `{your-api-key}` with your service key.\n",
       "\n",
       "Here's the curl command:\n",
       "\n",
       "```sh\n",
       "curl -X POST \"{your-endpoint-url}/openai/deployments/{deployment-id}/embeddings?api-version=2023-10-01\" \\\n",
       "-H \"Content-Type: application/json\" \\\n",
       "-H \"Authorization: Bearer {your-api-key}\" \\\n",
       "-d '{\n",
       "  \"input\": \"The food was delicious and the waiter was very friendly.\"\n",
       "}'\n",
       "```\n",
       "\n",
       "Make sure to replace `{deployment-id}` with your specific deployment ID as well.\n",
       "\n",
       "### Example JSON Output\n",
       "\n",
       "Once successfully executed, you will receive a JSON response containing the embeddings. Here's an example of what the output might look like:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"embedding\": [\n",
       "        0.1234, -0.5678, 0.9101, 0.1121, -0.3141, 0.5161, -0.7182,\n",
       "        0.8192, -0.9203, 1.0213, 1.1223, -1.2234, 1.3244, -1.4254, \n",
       "        1.5265, -1.6275, 1.7285, -1.8295, 1.9306, -2.0316, 2.1326, \n",
       "        -2.2337, 2.3347, -2.4357, 2.5368, -2.6378, 2.7388, -2.8398\n",
       "        // This would continue with many more values in the actual output\n",
       "      ]\n",
       "    }\n",
       "  ],\n",
       "  \"model\": \"text-embedding-ada-002\"\n",
       "}\n",
       "```\n",
       "\n",
       "The `embedding` array will contain a long list of floating-point numbers that represent the embedded vector for the given input text. The length and values of these vectors will depend on the specific model used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Show me an example in curl of using the Azure OpenAI embeddings REST endpoint. \n",
    "The prompt should be: \"The food was delicious and the waiter was very friendly...\"\n",
    "Include an example output JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Hereâ€™s an example of how you can use `curl` to send a request to the Azure OpenAI ChatCompletion REST endpoint, using the given JSON prompt.\n",
       "\n",
       "First, ensure you have the following:\n",
       "\n",
       "1. Azure endpoint URL for the OpenAI service (replace `YOUR_ENDPOINT_URL` with this value).\n",
       "2. An API key for authorization (replace `YOUR_API_KEY` with this value).\n",
       "3. The specific model deployment name (replace `YOUR_DEPLOYMENT_NAME` with this value).\n",
       "\n",
       "Here's the `curl` command:\n",
       "\n",
       "```sh\n",
       "curl -X POST https://YOUR_ENDPOINT_URL/openai/deployments/YOUR_DEPLOYMENT_NAME/chat/completions?api-version=2023-10-03 \\\n",
       "-H \"Content-Type: application/json\" \\\n",
       "-H \"Authorization: Bearer YOUR_API_KEY\" \\\n",
       "-d '{\n",
       "  \"messages\": [\n",
       "    {\n",
       "      \"role\": \"system\",\n",
       "      \"content\": \"You are an assistant that teaches people about AI.\"\n",
       "    },\n",
       "    {\n",
       "      \"role\": \"user\",\n",
       "      \"content\": \"Does Azure OpenAI support multiple languages?\"\n",
       "    },\n",
       "    {\n",
       "      \"role\": \"assistant\",\n",
       "      \"content\": \"Yes, Azure OpenAI supports several languages.\"\n",
       "    },\n",
       "    {\n",
       "      \"role\": \"user\",\n",
       "      \"content\": \"Do other Cognitive Services support translation?\"\n",
       "    }\n",
       "  ]\n",
       "}'\n",
       "```\n",
       "\n",
       "Here's an example of what the output JSON might look like (note that this is a hypothetical response and the actual response may vary):\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"id\": \"chatcmpl-abc123\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1696534567,\n",
       "  \"model\": \"chat-model\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Yes, other Azure Cognitive Services support translation as well. Azure Cognitive Services Translator Text can translate text in real-time, providing support for over 70 languages.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 50,\n",
       "    \"completion_tokens\": 25,\n",
       "    \"total_tokens\": 75\n",
       "  }\n",
       "}\n",
       "```\n",
       "\n",
       "Explanation of key fields in the response:\n",
       "\n",
       "- `id`: Unique ID for the completion.\n",
       "- `object`: Type of the object returned by the API.\n",
       "- `created`: Timestamp of when the completion was created.\n",
       "- `model`: The model that was used to generate the response.\n",
       "- `choices`: List of completion choices, each with a message role (`assistant`) and generated content.\n",
       "- `usage`: Token usage statistics, including prompt tokens, completion tokens, and total tokens.\n",
       "\n",
       "Make sure to replace placeholders with your actual endpoint URL, API key, and deployment name before running the command."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Show me an example in curl of using the Azure OpenAI ChatCompletion REST endpoint. \n",
    "The prompt should include the following json:\n",
    "\n",
    "{\n",
    "  \"messages\":[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are an assistant that teaches people about AI.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"Does Azure OpenAI support multiple languages?\"},\n",
    "    {\"role\": \"assistant\",\n",
    "     \"content\": \"Yes, Azure OpenAI supports several languages.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"Do other Cognitive Services support translation?\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Include an example output JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Below is an example of pseudocode demonstrating how to use Azure OpenAI's ChatCompletion feature to interact with an AI model. This example assumes you have already set up your Azure OpenAI resource and obtained the necessary API key and endpoint.\n",
       "\n",
       "```plaintext\n",
       "BEGIN\n",
       "    // Define the endpoint and API key\n",
       "    API_ENDPOINT = \"https://YOUR_AZURE_OPENAI_ENDPOINT\"\n",
       "    API_KEY = \"YOUR_AZURE_OPENAI_API_KEY\"\n",
       "\n",
       "    // Define the model ID you want to use\n",
       "    MODEL_ID = \"gpt-3.5-turbo\"\n",
       "\n",
       "    // Define the user prompt\n",
       "    USER_PROMPT = \"What is the capital of France?\"\n",
       "\n",
       "    // Create the request payload\n",
       "    REQUEST_PAYLOAD = {\n",
       "        \"model\": MODEL_ID,\n",
       "        \"messages\": [\n",
       "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "            {\"role\": \"user\", \"content\": USER_PROMPT}\n",
       "        ]\n",
       "    }\n",
       "\n",
       "    // Set up HTTP headers\n",
       "    HEADERS = {\n",
       "        \"Content-Type\": \"application/json\",\n",
       "        \"Authorization\": \"Bearer \" + API_KEY\n",
       "    }\n",
       "\n",
       "    // Function to send HTTP POST request\n",
       "    FUNCTION sendHttpPostRequest(url, headers, payload)\n",
       "        // Implementation for sending HTTP POST request\n",
       "        // This could be an HTTP library method in the actual programming language\n",
       "        RETURN HTTP_RESPONSE\n",
       "    END FUNCTION\n",
       "\n",
       "    // Send the request to Azure OpenAI API\n",
       "    RESPONSE = sendHttpPostRequest(API_ENDPOINT + \"/openai/deployments/\" + MODEL_ID + \"/chat/completions\", HEADERS, REQUEST_PAYLOAD)\n",
       "\n",
       "    // Parse the JSON response\n",
       "    RESPONSE_JSON = parseJson(RESPONSE)\n",
       "\n",
       "    // Extract the chat completion\n",
       "    CHAT_COMPLETION = RESPONSE_JSON[\"choices\"][0][\"message\"][\"content\"]\n",
       "\n",
       "    // Output the chat completion to the user\n",
       "    PRINT CHAT_COMPLETION\n",
       "END\n",
       "```\n",
       "\n",
       "### Explanation:\n",
       "1. **API_ENDPOINT and API_KEY**: Set these values based on your Azure OpenAI resource.\n",
       "2. **MODEL_ID**: The ID of the model you're using, e.g., \"gpt-3.5-turbo\".\n",
       "3. **USER_PROMPT**: The text input or question you want the model to respond to.\n",
       "4. **REQUEST_PAYLOAD**: The JSON payload sent to the API, including the model ID and the messages array.\n",
       "5. **HEADERS**: Standard HTTP headers including authorization using your API key.\n",
       "6. **sendHttpPostRequest**: A placeholder function for sending an HTTP POST request.\n",
       "7. **RESPONSE**: The result of the HTTP request.\n",
       "8. **RESPONSE_JSON**: Parsing the response to JSON.\n",
       "9. **CHAT_COMPLETION**: Extracting the generated response from the API.\n",
       "10. **PRINT**: Outputting the result.\n",
       "\n",
       "In a real programming language, you would replace the pseudocode with actual library calls to perform the HTTP request and handle JSON. For instance, in Python, you'd use `requests` and `json` modules to achieve this."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Show me an example in pseudocode of using the Azure OpenAI ChatCompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is:\n",
       "\n",
       "- ChatCompletion\n",
       "\n",
       "Here's why:\n",
       "\n",
       "OpenAI provides different REST endpoints for interacting with various models and functionalities. For interacting with GPT-4, which is designed to handle conversational contexts and interactive tasks more effectively than just generating plain text, the `ChatCompletion` endpoint is appropriate.\n",
       "\n",
       "- `Completion`: This endpoint is typically used for generating text completions given a prompt. It is more suitable for straightforward text generation tasks without the need for maintaining or understanding chat-specific context.\n",
       "\n",
       "- `Embeddings`: This endpoint is used for generating vector embeddings of text, which are numerical representations that can be used for tasks like text similarity, clustering, or as input features for machine learning models. It is not used for generating text or conversation.\n",
       "\n",
       "- `ChatCompletion`: This endpoint is specifically designed for models like GPT-4 that handle multi-turn conversations and chat interactions. It supports messages structured with roles (like `system`, `user`, and `assistant`), making it apt for chat-based applications where context and role distinction are essential.\n",
       "\n",
       "In summary, `ChatCompletion` is the right endpoint to use for GPT-4, particularly for tasks that involve conversational AI and maintaining an interactive dialogue context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Which REST endpoint should you use to interact with a GPT-4 model?\n",
    "\n",
    "- Completion \n",
    "- Embeddings\n",
    "- ChatCompletion\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is:\n",
       "\n",
       "- **GetChatCompletions()**\n",
       "\n",
       "### Explanation:\n",
       "\n",
       "In the context of the .NET SDK for interacting with an API that provides chat-based completions (commonly associated with services like OpenAI's GPT-3.5 or later), `GetChatCompletions()` would be the method you use to call the ChatCompletion API.\n",
       "\n",
       "Here's a breakdown of the options and why `GetChatCompletions()` is the correct one:\n",
       "\n",
       "- **ChatMessage()**: This does not seem to fit the common naming conventions for invoking a completion endpoint. It's more likely to represent an object or class related to an individual message or chat rather than a method to call an endpoint.\n",
       "\n",
       "- **GetCompletions()**: Typically, this would be used for a more general completion API, which might return text completions based on a prompt. However, it doesn't explicitly specify that itâ€™s for chat completions. \n",
       "\n",
       "- **GetChatCompletions()**: This method name explicitly suggests that it retrieves chat completions, aligning perfectly with the purpose of calling the ChatCompletion API. It conveys clearly that the function's responsibility is to handle chat-based completion scenarios.\n",
       "\n",
       "Always refer to the official documentation of the SDK for the most accurate and updated method names and usage examples, as APIs can have specific names and parameters that match their use cases precisely."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "When using the .NET SDK, which method should you use to call the ChatCompletion API?\n",
    "\n",
    "- ChatMessage()\n",
    "- GetChatCompletions()\n",
    "- GetCompletions()\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is:\n",
       "\n",
       "- `openai.ChatCompletion.create()`\n",
       "\n",
       "### Explanation:\n",
       "\n",
       "- **`openai.ChatCompletion.create()`**: This is the correct method to call the ChatCompletion API using the OpenAI Python SDK. The `create` method is used to initiate a chat completion request, which allows you to send a series of messages and receive a response from the model. This method fits the typical use case described by the naming conventions in the OpenAI API SDK, where `create` is used to generate new completions.\n",
       "\n",
       "- **`openai.ChatCompletion.get()`**: This method does not exist. The `get` method is typically used to retrieve an existing resource or object in many APIs, but in the context of generating text or chat completions, you typically want to use `create` to generate new content instead.\n",
       "\n",
       "- **`openai.chat.complete()`**: This method also does not exist. The correct namespace and method to invoke the chat completion feature involve the `ChatCompletion` class and the `create` method within it.\n",
       "\n",
       "Therefore, to call the ChatCompletion API with the OpenAI Python SDK, you should use `openai.ChatCompletion.create()`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "When using the Python SDK, which method should you use to call the ChatCompletion API?\n",
    "\n",
    "- openai.ChatCompletion.get()\n",
    "- openai.ChatCompletion.create()\n",
    "- openai.chat.complete()\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
