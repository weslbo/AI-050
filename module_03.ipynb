{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply prompt engineering with Azure OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run library.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Prompt engineering is a concept most commonly associated with the development and fine-tuning of prompts for natural language processing (NLP) models, especially large language models like GPT-4. These models generate responses based on the input they receive, and the quality and nature of the output heavily depend on how the input, or \"prompt,\" is structured. Here’s a more detailed breakdown:\n",
       "\n",
       "### Key Aspects of Prompt Engineering:\n",
       "\n",
       "1. **Input Design:** Crafting prompts that are clear, concise, and designed to elicit the desired response from the language model.\n",
       "  \n",
       "2. **Task Specification:** Clearly defining the task for the model helps manage expectations and outcomes. For instance, a prompt designed to generate a story will differ significantly from one aimed at translating text.\n",
       "  \n",
       "3. **Contextual Information:** Including relevant context in the prompt to guide the model towards more accurate and contextually appropriate responses. This might include background information, specific instructions, or examples.\n",
       "  \n",
       "4. **Iterative Refinement:** Continuously refining and tweaking prompts based on the responses received. This iterative process helps to optimize the prompt for better performance and accuracy.\n",
       "\n",
       "5. **Token Management:** Understanding the token limits of models (such as the max token count for input and output in GPT-3 and GPT-4) and designing prompts to fit within those constraints while still conveying the necessary information.\n",
       "\n",
       "### Practical Applications:\n",
       "\n",
       "- **Content Creation:** Generating articles, stories, and other types of content.\n",
       "- **Customer Support:** Drafting responses to customer inquiries.\n",
       "- **Programming Assistance:** Generating code snippets or providing explanations of code.\n",
       "- **Educational Tools:** Crafting educational content and explanations.\n",
       "- **Translation:** Translating text from one language to another with contextual appropriateness.\n",
       "\n",
       "### Examples:\n",
       "\n",
       "1. **Content Creation:**\n",
       "   - Poor Prompt: \"Write a story.\"\n",
       "   - Improved Prompt: \"Write a 500-word science fiction story set on Mars in the year 2075, focusing on the experiences of a botanist working to terraform the planet.\"\n",
       "\n",
       "2. **Programming Help:**\n",
       "   - Poor Prompt: \"Explain Python code.\"\n",
       "   - Improved Prompt: \"Explain the following Python code snippet, focusing on how it handles list comprehension and what the resultant list contains:\n",
       "   ```\n",
       "   numbers = [1, 2, 3, 4, 5]\n",
       "   squared = [n**2 for n in numbers]\n",
       "   ```\"\n",
       "\n",
       "By honing these aspects, prompt engineering enhances the usability of language models, enabling them to perform more accurate and useful tasks based on tailored inputs. This practice is particularly important for maximizing the efficiency and effectiveness of AI systems in various real-world applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat \n",
    "\n",
    "What is Prompt Engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In the context of Azure OpenAI, \"primary,\" \"supporting,\" and \"grounding\" content are terms often used to describe different aspects and strategies for utilizing and managing the AI models effectively. Let's break down each term:\n",
       "\n",
       "### Primary Content\n",
       "Primary content refers to the main text, data, or information that you are directly working with or generating using the OpenAI models. This is the core content that meets your specific use case or requirement. For example:\n",
       "- For a chatbot, the primary content would be the responses generated by the model.\n",
       "- For a content creation tool, it would be the articles, blog posts, or marketing copy generated.\n",
       "\n",
       "### Supporting Content\n",
       "Supporting content includes additional information or supplementary data that enhances or enriches the primary content. It can be used to provide context, examples, or explanations that help improve the primary content. For example:\n",
       "- In a language translation application, supporting content might include glossaries or contextual examples to ensure accurate translations.\n",
       "- In a writing assistant tool, supporting content could be grammar tips, style suggestions, or factual references that help refine the generated text.\n",
       "\n",
       "### Grounding Content\n",
       "Grounding content is high-quality reference material that informs and guides the AI's responses to ensure accuracy, relevance, and credibility. Grounding content is critical for preventing the AI from generating misleading or incorrect information. Examples include:\n",
       "- Reference databases, like Wikipedia or a company's internal knowledge base, that provide factual context.\n",
       "- Real-time data feeds for applications requiring up-to-date information, such as financial news summaries or weather forecasts.\n",
       "- Domain-specific knowledge bases relevant to the task at hand, ensuring that the AI-generated content aligns with the established facts and best practices.\n",
       "\n",
       "In practice, ensuring that the AI models have access to reliable grounding content can significantly enhance the quality of the generated responses, making them more trustworthy and appropriate for professional or critical applications.\n",
       "\n",
       "### Implementing in Azure OpenAI\n",
       "In Azure OpenAI, managing primary, supporting, and grounding content would typically involve:\n",
       "1. **Primary Content Management**: Setting up the initial prompts and defining the use cases you need the model to address.\n",
       "2. **Supporting Content Integration**: Providing additional data inputs, context, and parameters that the model can use to improve its responses.\n",
       "3. **Grounding Content Access**: Connecting the model to authoritative data sources and ensuring it references accurate information when generating content.\n",
       "\n",
       "Properly leveraging these types of content can help you optimize the performance, reliability, and utility of OpenAI models in your applications."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "What is Primary, supporting, and grounding content, in the context of Azure OpenAI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Interest in summer school program webinars\n",
       "- Request for ideas on topics such as AI and web development\n",
       "- Topics of particular interest: AI, webinar dates, submission deadlines"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "---\n",
    "Thanks for your interest in our summer school program.\n",
    "We’re looking for your ideas for webinars on topics such as AI, web development, … <more…>\n",
    "---\n",
    "\n",
    "Topics I'm very interested in: AI, webinar dates, submission deadlines\n",
    "\n",
    "Extract the key points from the above email, and put them in a bulleted list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The field of artificial intelligence (AI) was formally founded as an academic discipline in 1956. This event took place during the Dartmouth Conference, organized by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon. The conference marked the official beginning of artificial intelligence as a research field distinct from other areas of study. Alan Turing, however, is considered one of the pioneers of the field, having conducted substantial early research in what he termed \"machine intelligence\" before AI was formally established."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "---\n",
    "Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and uses learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.\n",
    "\n",
    "AI technology is widely used throughout industry, government, and science. Some high-profile applications include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go).[2] However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[3][4]\n",
    "\n",
    "Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence.[5] Artificial intelligence was founded as an academic discipline in 1956.[6] The field went through multiple cycles of optimism,[7][8] followed by periods of disappointment and loss of funding, known as AI winter.[9][10] Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques,[11] and after 2017 with the transformer architecture.[12] This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.[13]\n",
    "\n",
    "The growing use of artificial intelligence in the 21st century is influencing a societal and economic shift towards increased automation, data-driven decision-making, and the integration of AI systems into various economic sectors and areas of life, impacting job markets, healthcare, government, industry, and education. This raises questions about the long-term effects, ethical implications, and risks of AI, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
    "\n",
    "The various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field's long-term goals.[14]\n",
    "\n",
    "To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[15]\n",
    "---\n",
    "\n",
    "Where and when did the field of AI start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Most common complaints:\n",
       "- The movie was too long.\n",
       "- The special effects were terrible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "---\n",
    "Review: The writing was good but the movie was too long.\n",
    "Review: The special effects were terrible.\n",
    "<more>…\n",
    "---\n",
    "\n",
    "Summarize the reviews above.\n",
    "Most common complaints:\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here's a table in markdown format with six animals, including their genus and species:\n",
       "\n",
       "```markdown\n",
       "| Animal      | Genus       | Species         |\n",
       "|-------------|-------------|-----------------|\n",
       "| African Lion| Panthera    | Panthera leo    |\n",
       "| Gray Wolf   | Canis       | Canis lupus     |\n",
       "| Bengal Tiger| Panthera    | Panthera tigris |\n",
       "| Red Fox     | Vulpes      | Vulpes vulpes   |\n",
       "| Common Dolphin| Delphinus| Delphinus delphis|\n",
       "| Bald Eagle  | Haliaeetus  | Haliaeetus leucocephalus |\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat \n",
    "\n",
    "Write a table in markdown with 6 animals in it, with their genus and species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure thing, partner! Here's an example of how the response might look:\n",
       "\n",
       "---\n",
       "\n",
       "**System:** You are a casual, helpful assistant. You will talk like an American old western film character.\n",
       "\n",
       "**User:** Can you direct me to the library?\n",
       "\n",
       "**Assistant:** Well howdy there, stranger! If yer lookin' fer the library, ya just gotta mosey on down Main Street, take a left at the ol' saloon, and you'll find it sittin' right next to the General Store. Happy trails, and don’t go gettin' lost now, ya hear?\n",
       "\n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "When using the ChatCompletions API, a system message sets context that can affect completions. \n",
    "\n",
    "{\"role\": \"system\", \"content\": \"You are a casual, helpful assistant. You will talk like an American old western film character.\"},\n",
    "{\"role\": \"user\", \"content\": \"Can you direct me to the library?\"}\n",
    "\n",
    "Provide me with an example output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": \"positive\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Including previous messages helps retain the context and style of a conversation\n",
    "Starting a conversation with user-defined messages and responses (few shot learning) sets examples for the expected responses\n",
    "\n",
    "{\"role\": \"system\", \"content\": \"You are an assistant that evaluates the sentiment of customer feedback.\"},\n",
    "\n",
    "{\"role\": \"user\", \"content\": \"That was an awesome experience\"},\n",
    "{\"role\": \"assistant\", \"content\": \"positive\"},\n",
    "\n",
    "{\"role\": \"user\", \"content\": \"I won't do that again\"},\n",
    "{\"role\": \"assistant\", \"content\": \"negative\"},\n",
    "\n",
    "{\"role\": \"user\", \"content\": \"That was not worth my time\"},\n",
    "{\"role\": \"assistant\", \"content\": \"negative\"},\n",
    "\n",
    "{\"role\": \"user\", \"content\": \"You can't miss this\"}\n",
    "\n",
    "\n",
    "Provide an example output in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Let's break down the reasoning step by step to determine which sport is easiest to learn but hardest to master.\n",
       "\n",
       "1. **Defining \"Easiest to Learn\" and \"Hardest to Master\"**:\n",
       "   - \"Easiest to learn\": A sport where basic rules and fundamental skills can be picked up quickly by beginners.\n",
       "   - \"Hardest to master\": A sport that requires a high level of skill, strategy, and experience to be played at an expert or professional level.\n",
       "\n",
       "2. **Candidates for Easiest to Learn**:\n",
       "   - We'll consider a few sports known for their accessibility: \n",
       "     - Soccer (association football)\n",
       "     - Basketball\n",
       "     - Table Tennis\n",
       "     - Running\n",
       "     - Swimming\n",
       "\n",
       "3. **Evaluating Accessibility**:\n",
       "   - Soccer: Anyone can start kicking a ball around and understand basic rules pretty quickly.\n",
       "   - Basketball: Dribbling and shooting a ball are fairly simple to try initially.\n",
       "   - Table Tennis: Hitting a ball back and forth on a small table is relatively straightforward.\n",
       "   - Running: Putting one foot in front of the other is an innate human ability.\n",
       "   - Swimming: Floating and basic strokes can be learned with some initial instructions.\n",
       "\n",
       "4. **Evaluating Difficulty to Master**:\n",
       "   - Soccer: Advanced tactics, positioning, and technical skills like precise passing and shooting require years of training.\n",
       "   - Basketball: Mastery involves complex dribbling skills, shooting accuracy, defensive tactics, and teamwork.\n",
       "   - Table Tennis: At high levels, the sport requires lightning-fast reactions, spin control, and precision.\n",
       "   - Running: While strategy and conditioning are important, it is possibly less complex in terms of technical skills.\n",
       "   - Swimming: High-level swimming requires a lot of technique refinement and conditioning, but it might still be less complex compared to sports with ball interaction.\n",
       "\n",
       "5. **Combining Both Criteria**:\n",
       "   - Soccer seems to be highly accessible because it’s easy to start playing and understanding the basics (kick the ball, aim at the goal, follow simple rules).\n",
       "   - However, mastering soccer requires enormous dedication, intricate tactical knowledge, refined technical skills, and excellent physical conditioning.\n",
       "\n",
       "6. **Final Consideration**:\n",
       "   - While other sports like basketball and table tennis also fit the criteria well, soccer stands out because it combines a simple, universal appeal with demanding mastery requirements shared by both individual brilliance and team dynamics.\n",
       "\n",
       "**Conclusion**:\n",
       "Based on this analysis, **Soccer** is arguably the sport that is easiest to learn but hardest to master. It’s easy for beginners to pick up the basics and start having fun quickly, yet it takes years of dedicated practice, strategic understanding, and skill refinement to reach a professional level."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Ask a model to break down its response and explain its reasoning.\n",
    "What sport is easiest to learn but hardest to master? Give a step by step approach of your thoughts, ending in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is:\n",
       "\n",
       "- By providing clear and descriptive instructions\n",
       "\n",
       "This approach is beneficial because:\n",
       "\n",
       "1. **Guidance and Context**: Clear and descriptive instructions provide the model with necessary context and detailed guidance, which helps in generating more accurate and relevant responses.\n",
       "2. **Reduction of Ambiguity**: Vague prompts can lead to a wide range of interpretations, causing the model to produce less specific or off-target results. Complex instructions that are difficult to understand can confuse the model.\n",
       "3. **Efficiency**: Well-defined prompts help the model to understand exactly what is being asked, thus optimizing the computational efficiency and resulting in quicker and more accurate answers.\n",
       "4. **Improved Training**: Consistent, clear prompts contribute to better model training and fine-tuning, ensuring improved performance over time.\n",
       "\n",
       "In summary, providing clear and descriptive instructions ensures that the model can effectively understand and process the input, leading to optimized performance and more useful outputs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "How can developers optimize the performance of Azure OpenAI models?\n",
    "\n",
    "- By using complex instructions that are difficult to understand \n",
    "- By providing clear and descriptive instructions\n",
    "- By using vague prompts\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is:\n",
       "\n",
       "- To give the model instructions, perspective, or other information helpful to guide its response\n",
       "\n",
       "Explanation:\n",
       "\n",
       "The system message in a prompt serves the purpose of guiding the model in its response. It provides instructions, sets the context, and establishes any rules or guidelines that the model should follow when generating an answer. This helps ensure that the model's output is relevant, coherent, and aligned with the desired outcome. Unlike providing a specific answer (which would limit the model's generative capabilities) or serving as filler information (which would not be useful), the system message is crucial for effectively steering the model's behavior and performance."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "What is the purpose of the system message in a prompt?\n",
    "\n",
    "- To give the model instructions, perspective, or other information helpful to guide its response\n",
    "- To give the model a specific answer to generate\n",
    "- To provide filler information to the model\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is: **To enable the model to continue responding in a similar way and allow the user to reference previous content in subsequent queries.**\n",
       "\n",
       "Explanation:\n",
       "\n",
       "Providing conversation history to an AI model is crucial for several reasons:\n",
       "\n",
       "1. **Context Maintenance:** The conversation history gives the model context about the ongoing dialogue, allowing it to generate more relevant and coherent responses. Without this context, the model might provide disjointed or unrelated answers.\n",
       "\n",
       "2. **User Experience:** The history allows the user to reference previous content in subsequent queries. This makes the interaction more natural and fluid, similar to a human conversation where both parties remember previous parts of the discussion.\n",
       "\n",
       "3. **Consistent Responses:** By keeping track of the conversation, the model can maintain a consistent tone and style, ensuring that responses are appropriate to the prior dialogue.\n",
       "\n",
       "In contrast, the other options are either incorrect or not relevant:\n",
       "\n",
       "- **Providing conversation history to an AI model is irrelevant and has no effect on the AI's performance.** This is not true. The performance and relevance of the AI's responses greatly depend on its ability to reference past conversation history.\n",
       "\n",
       "- **To limit the number of input tokens used by the model.** This is incorrect. Including conversation history actually increases the number of input tokens. However, it is managed by deciding how much of the history to retain to balance context relevance and token limitations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "What is the purpose of providing conversation history to an AI model?\n",
    "\n",
    "- Providing conversation history to an AI model is irrelevant and has no effect on the AI's performance.\n",
    "- To limit the number of input tokens used by the model\n",
    "- To enable the model to continue responding in a similar way and allow the user to reference previous content in subsequent queries\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
