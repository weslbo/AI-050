{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images with Azure OpenAI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run library.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dalleproduse.blob.core.windows.net/private/images/f6b1bc2d-50ce-48e0-a81d-71e9170e3515/generated_00.png?se=2024-05-29T12%3A12%3A03Z&sig=LbCVFyW%2BAmCViZ8uK0QJq6J%2BrcwBAU7xWSa6%2BvX4BxM%3D&ske=2024-06-02T13%3A36%3A59Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2024-05-26T13%3A36%3A59Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%dalle\n",
    "\n",
    "a highland cow in a field on the coast of Scotland, digital art style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To call the Azure DALL-E 3 image generation REST endpoint using `curl`, you'll need the following:\n",
       "1. Azure subscription with access to the DALL-E 3 service.\n",
       "2. An endpoint and an API key provisioned within your Azure portal.\n",
       "\n",
       "Below is an example of how you can achieve this. Please replace `https://your-endpoint.cognitiveservices.azure.com` with your actual endpoint, and `your_api_key` with your actual API key.\n",
       "\n",
       "### Step-by-Step Instructions:\n",
       "\n",
       "1. Obtain the required endpoint URL and API key from your Azure Cognitive Services resource.\n",
       "\n",
       "2. Construct your `curl` request. Here is a basic example using a sample prompt:\n",
       "\n",
       "### Sample `curl` Request\n",
       "\n",
       "```sh\n",
       "curl -X POST \"https://your-endpoint.cognitiveservices.azure.com/dalle-3/v1/images/generate\" \\\n",
       "     -H \"Content-Type: application/json\" \\\n",
       "     -H \"Ocp-Apim-Subscription-Key: your_api_key\" \\\n",
       "     -d '{\n",
       "           \"prompt\": \"A futuristic cityscape with flying cars and neon lights\"\n",
       "         }'\n",
       "```\n",
       "\n",
       "### Sample Prompt and Explanation\n",
       "- **Prompt:** \"A futuristic cityscape with flying cars and neon lights\"\n",
       "- This prompt is a text input that describes the type of image you want the DALL-E model to generate.\n",
       "\n",
       "### Expected Output\n",
       "\n",
       "The response typically contains the generated image's URL or the image data itself in the form of an encoded string (e.g., base64). Here's an example structure of what the JSON response might look like:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"images\": [\n",
       "    {\n",
       "      \"url\": \"https://your-endpoint.cognitiveservices.azure.com/images/generated-image-id.png\"\n",
       "    }\n",
       "  ]\n",
       "}\n",
       "```\n",
       "\n",
       "In practice, the actual structure may vary based on Azure’s specific implementation of the DALL-E 3 service. Make sure to consult Azure’s official documentation for precise details and updates.\n",
       "\n",
       "### Note:\n",
       "- The request might take a few seconds to process, depending on the complexity of the prompt and current server load.\n",
       "- Ensure you handle the response appropriately in your application, managing errors and edge cases (like rate limiting or invalid prompts).\n",
       "\n",
       "Feel free to adapt and expand on this example to suit your specific use case and Azure configuration. Always refer to Azure’s official documentation for the most accurate and updated information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "How do I call the Azure dalle-3 images generation REST endpoint using curl?\n",
    "\n",
    "Include a sample prompt and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! As of my knowledge cutoff date in October 2023, to use the Azure OpenAI DALL-E 3 API you need to follow these steps:\n",
       "\n",
       "1. **Create an Azure OpenAI resource**: You need to set up an account with Azure and create an OpenAI resource through the Azure portal, which will provide you with an endpoint and a key for making API requests.\n",
       "\n",
       "2. **Install necessary libraries**: You'll need the `requests` library to make HTTP requests to the API. You can install it using pip if you don't have it already:\n",
       "    ```sh\n",
       "    pip install requests\n",
       "    ```\n",
       "\n",
       "3. **Python script to make a call to the DALL-E 3 API**: Here’s an example in Python demonstrating how you can use this API.\n",
       "\n",
       "Here’s a complete example that demonstrates how to generate an image using DALL-E 3 via the Azure OpenAI API:\n",
       "\n",
       "```python\n",
       "import requests\n",
       "import json\n",
       "\n",
       "# Replace these with your Azure OpenAI endpoint and key\n",
       "api_base_url = \"https://YOUR_RESOURCE_NAME.openai.azure.com/\"\n",
       "api_version = \"v1\"\n",
       "api_key = \"YOUR_API_KEY\"\n",
       "\n",
       "# Endpoint URL for the DALL-E 3 API\n",
       "endpoint = f\"{api_base_url}openai/deployments/YOUR_DEPLOYMENT_NAME/images/generate?api-version={api_version}\"\n",
       "\n",
       "# Request headers\n",
       "headers = {\n",
       "    \"Content-Type\": \"application/json\",\n",
       "    \"api-key\": api_key,\n",
       "}\n",
       "\n",
       "# Data payload for image generation\n",
       "data = {\n",
       "    \"prompt\": \"A futuristic cityscape with flying cars and tall skyscrapers\",\n",
       "    \"n\": 1,  # Number of images to generate\n",
       "    \"size\": \"1024x1024\"  # Desired image size\n",
       "}\n",
       "\n",
       "# Perform the API call\n",
       "response = requests.post(endpoint, headers=headers, json=data)\n",
       "\n",
       "if response.status_code == 200:\n",
       "    result = response.json()\n",
       "    images = result[\"data\"]\n",
       "    \n",
       "    for idx, image_data in enumerate(images):\n",
       "        image_url = image_data[\"url\"]\n",
       "        print(f\"Image {idx + 1}: {image_url}\")\n",
       "else:\n",
       "    print(f\"Error: {response.status_code}\")\n",
       "    print(response.json())\n",
       "```\n",
       "\n",
       "In this example:\n",
       "- Replace `YOUR_RESOURCE_NAME` with the name of your Azure OpenAI resource.\n",
       "- Replace `YOUR_API_KEY` with the API key for your Azure OpenAI resource.\n",
       "- Replace `YOUR_DEPLOYMENT_NAME` with the deployment name you assigned when you set up your DALL-E 3 model in Azure.\n",
       "- Modify the `prompt` in `data` with the text prompt you want to use to generate images.\n",
       "- Optionally alter the `n` and `size` values according to your requirements.\n",
       "\n",
       "Make sure your Azure OpenAI resource is correctly configured and you have the necessary permissions to use the API.\n",
       "\n",
       "Please verify and adjust this code according to any updates or changes in Azure's API structure and offerings that might have occurred after the last knowledge update in October 2023."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Show me an example in python of using the Azure OpenAI DallE-3 api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is **DALL-E**.\n",
       "\n",
       "DALL-E is a model developed by OpenAI specifically for generating images from textual descriptions. It takes a text input and produces a corresponding image, leveraging its trained capabilities to understand and visualize the text in a coherent and creative way.\n",
       "\n",
       "On the other hand:\n",
       "\n",
       "- **GPT-3.5-Turbo** (assuming it refers to GPT-3.5 or an enhanced version of GPT-3) is a language model designed for generating and understanding text. It is not capable of creating images.\n",
       "\n",
       "- **Text-Davinci** is also a variant of the GPT-3 language models focused on text processing, thus suitable for generating and understanding text rather than images.\n",
       "\n",
       "Therefore, if you are looking to generate images using Azure OpenAI, DALL-E is the appropriate choice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "You want to use a model in Azure OpenAI to generate images. Which model should you use?\n",
    "\n",
    "- DALL-E\n",
    "- GPT-35-Turbo\n",
    "- Text-Davinci\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You should use **DALL-E** to explore image generation in Azure OpenAI Studio.\n",
       "\n",
       "**Explanation:** DALL-E is a specific model developed by OpenAI that is designed for generating images from textual descriptions. When you want to generate images based on prompts or descriptions, DALL-E is the appropriate tool because it has been trained to understand and create visual content from text inputs. \n",
       "\n",
       "- **Completions:** This playground is used for text generation, continuation, or completion based on an input prompt, such as generating paragraphs, code, dialogues, etc.\n",
       "- **Chat:** This is used for conversational AI, where the model simulates a conversation with a user, similar to how a chatbot operates.\n",
       "\n",
       "Thus, for image generation, the DALL-E playground is the correct choice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "Which playground in Azure OpenAI Studio should you use to explore image generation\n",
    "\n",
    "- Completions\n",
    "- DALL-E\n",
    "- Chat\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The correct answer is:\n",
       "\n",
       "- The number of images to be generated\n",
       "\n",
       "Explanation:\n",
       "In the context of an API request to generate images, the `n` parameter typically specifies the number of images that you want the API to generate. It allows you to control how many distinct images you receive in response to your request. This is important when you need multiple variations of an image or when conducting experiments that require several outputs to choose from. The description of the desired image and the size of the image are usually specified by other parameters in the API request."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%chat\n",
    "\n",
    "In an API request to generate images, what does the n parameter indicate?\n",
    "\n",
    "- The description of the desired image \n",
    "- The number of images to be generated\n",
    "- The size of the image to be generated\n",
    "\n",
    "Choose the correct answer and explain why"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
